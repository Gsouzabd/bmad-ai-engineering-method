import express from 'express'
import { authenticateToken } from './auth.js'
import { supabase } from '../config/supabase.js'
import OpenAI from 'openai'
import dotenv from 'dotenv'

// Carregar vari√°veis de ambiente
dotenv.config()

// Importar fun√ß√µes MCP para execu√ß√£o das ferramentas
import { google } from 'googleapis'
import CryptoJS from 'crypto-js'

// Configurar OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'sua_openai_api_key_aqui'
})

// Chave de criptografia para credenciais
const ENCRYPTION_KEY = process.env.ENCRYPTION_KEY || 'your-secret-key-32-chars-long!'

// Fun√ß√£o para descriptografar dados
const decrypt = (ciphertext) => {
  const bytes = CryptoJS.AES.decrypt(ciphertext, ENCRYPTION_KEY)
  return bytes.toString(CryptoJS.enc.Utf8)
}

// Fun√ß√£o para obter credenciais do usu√°rio
const getUserCredentials = async (userId) => {
  const { data, error } = await supabase
    .from('user_credentials')
    .select('*')
    .eq('user_id', userId)
    .eq('is_valid', true)
    .single()

  if (error || !data) {
    throw new Error('Credenciais Google n√£o encontradas ou inv√°lidas')
  }

  return {
    clientId: data.client_id,
    clientSecret: decrypt(data.client_secret),
    accessToken: decrypt(data.access_token),
    refreshToken: decrypt(data.refresh_token)
  }
}

// Fun√ß√£o para executar ferramentas MCP
const executeMCPTool = async (toolName, params, userId) => {
  try {
    // Obter credenciais do usu√°rio
    const credentials = await getUserCredentials(userId)
    
    switch (toolName) {
      case 'gdrive_list_files':
        return await executeGDriveListFiles(credentials, params)
      case 'gdrive_read_file':
        return await executeGDriveReadFile(credentials, params)
      case 'sheets_read_values':
        return await executeSheetsReadValues(credentials, params)
      case 'sheets_write_values':
        return await executeSheetsWriteValues(credentials, params)
      default:
        throw new Error(`Ferramenta n√£o suportada: ${toolName}`)
    }
  } catch (error) {
    console.error(`‚ùå Erro ao executar ferramenta MCP ${toolName}:`, error)
    throw error
  }
}

// Fun√ß√£o para executar gdrive.list_files
const executeGDriveListFiles = async (credentials, params) => {
  try {
    const oauth2Client = new google.auth.OAuth2(
      credentials.clientId,
      credentials.clientSecret
    )
    
    oauth2Client.setCredentials({
      access_token: credentials.accessToken,
      refresh_token: credentials.refreshToken
    })

    const drive = google.drive({ version: 'v3', auth: oauth2Client })
    
    const response = await drive.files.list({
      pageSize: params.pageSize || 10,
      fields: 'files(id,name,mimeType,createdTime,modifiedTime)',
      orderBy: 'modifiedTime desc'
    })

    return {
      files: response.data.files,
      total: response.data.files.length
    }
  } catch (error) {
    throw new Error('Erro ao listar arquivos do Drive: ' + error.message)
  }
}

// Fun√ß√£o para executar gdrive.read_file
const executeGDriveReadFile = async (credentials, params) => {
  try {
    const oauth2Client = new google.auth.OAuth2(
      credentials.clientId,
      credentials.clientSecret
    )
    
    oauth2Client.setCredentials({
      access_token: credentials.accessToken,
      refresh_token: credentials.refreshToken
    })

    const drive = google.drive({ version: 'v3', auth: oauth2Client })
    
    // Primeiro, obter metadados do arquivo
    const fileMetadata = await drive.files.get({
      fileId: params.fileId,
      fields: 'id,name,mimeType,size'
    })
    
    let content = ''
    const mimeType = fileMetadata.data.mimeType
    
    // Verificar se √© um Google Docs/Sheets/Slides (precisa de export)
    if (mimeType.includes('application/vnd.google-apps')) {
      let exportMimeType = 'text/plain'
      
      if (mimeType.includes('document')) {
        exportMimeType = 'text/plain' // Google Docs -> texto
      } else if (mimeType.includes('spreadsheet')) {
        exportMimeType = 'text/csv' // Google Sheets -> CSV
      } else if (mimeType.includes('presentation')) {
        exportMimeType = 'text/plain' // Google Slides -> texto
      }
      
      // Exportar o arquivo
      const exportResponse = await drive.files.export({
        fileId: params.fileId,
        mimeType: exportMimeType
      })
      
      content = exportResponse.data
    } else {
      // Arquivo normal - download direto
      const response = await drive.files.get({
        fileId: params.fileId,
        alt: 'media'
      })
      
      content = response.data
    }

    return {
      fileId: params.fileId,
      fileName: fileMetadata.data.name,
      mimeType: fileMetadata.data.mimeType,
      size: fileMetadata.data.size,
      content: content
    }
  } catch (error) {
    throw new Error('Erro ao ler arquivo do Drive: ' + error.message)
  }
}

// Fun√ß√£o para executar sheets.read_values
const executeSheetsReadValues = async (credentials, params) => {
  try {
    const oauth2Client = new google.auth.OAuth2(
      credentials.clientId,
      credentials.clientSecret
    )
    
    oauth2Client.setCredentials({
      access_token: credentials.accessToken,
      refresh_token: credentials.refreshToken
    })

    const sheets = google.sheets({ version: 'v4', auth: oauth2Client })
    
    const response = await sheets.spreadsheets.values.get({
      spreadsheetId: params.spreadsheetId,
      range: params.range
    })

    return {
      values: response.data.values || [],
      range: response.data.range
    }
  } catch (error) {
    console.error('‚ùå Erro detalhado ao ler planilha:', {
      message: error.message,
      code: error.code,
      status: error.status,
      spreadsheetId: params.spreadsheetId,
      range: params.range
    })
    
    if (error.code === 404 || error.message.includes('not found')) {
      throw new Error(`Planilha n√£o encontrada. Verifique se o ID '${params.spreadsheetId}' est√° correto e se voc√™ tem permiss√£o para acess√°-la.`)
    } else if (error.code === 403) {
      throw new Error(`Acesso negado √† planilha '${params.spreadsheetId}'. Verifique as permiss√µes.`)
    } else {
      throw new Error('Erro ao ler planilha: ' + error.message)
    }
  }
}

// Fun√ß√£o para executar sheets.write_values
const executeSheetsWriteValues = async (credentials, params) => {
  try {
    const oauth2Client = new google.auth.OAuth2(
      credentials.clientId,
      credentials.clientSecret
    )
    
    oauth2Client.setCredentials({
      access_token: credentials.accessToken,
      refresh_token: credentials.refreshToken
    })

    const sheets = google.sheets({ version: 'v4', auth: oauth2Client })
    
    const response = await sheets.spreadsheets.values.update({
      spreadsheetId: params.spreadsheetId,
      range: params.range,
      valueInputOption: 'RAW',
      resource: {
        values: params.values
      }
    })

    return {
      updatedRows: response.data.updatedRows,
      updatedColumns: response.data.updatedColumns,
      updatedCells: response.data.updatedCells
    }
  } catch (error) {
    console.error('‚ùå Erro detalhado ao escrever na planilha:', {
      message: error.message,
      code: error.code,
      status: error.status,
      spreadsheetId: params.spreadsheetId,
      range: params.range
    })
    
    if (error.code === 404 || error.message.includes('not found')) {
      throw new Error(`Planilha n√£o encontrada. Verifique se o ID '${params.spreadsheetId}' est√° correto e se voc√™ tem permiss√£o para acess√°-la.`)
    } else if (error.code === 403) {
      throw new Error(`Acesso negado √† planilha '${params.spreadsheetId}'. Verifique as permiss√µes de escrita.`)
    } else {
      throw new Error('Erro ao escrever na planilha: ' + error.message)
    }
  }
}

const router = express.Router()

// Middleware para autentica√ß√£o SSE via query string
const authenticateSSE = async (req, res, next) => {
  try {
    const token = req.query.token || req.headers['authorization']?.split(' ')[1]

    if (!token) {
      return res.status(401).json({ error: 'Token de acesso necess√°rio' })
    }

    // Em desenvolvimento, permitir tokens mock
    if ((process.env.NODE_ENV === 'development' || !process.env.SUPABASE_URL || process.env.SUPABASE_URL.includes('placeholder')) && token === 'mock_token') {
      req.user = { id: '55ccaa1e-34a2-42a2-ba1f-32dfb7c6320c', email: 'dev@example.com' }
      return next()
    }

    // Verificar token com Supabase
    const { data: { user }, error } = await supabase.auth.getUser(token)
    
    if (error || !user) {
      return res.status(403).json({ error: 'Token inv√°lido' })
    }

    req.user = user
    next()
  } catch (error) {
    return res.status(403).json({ error: 'Token inv√°lido' })
  }
}

// Fun√ß√µes auxiliares para tracking de ferramentas
const getToolDisplayName = (toolName) => {
  const displayNames = {
    'gdrive_list_files': 'Listar Arquivos do Drive',
    'gdrive_read_file': 'Ler Arquivo do Drive',
    'sheets_read_values': 'Ler Planilha',
    'sheets_write_values': 'Escrever Planilha'
  }
  return displayNames[toolName] || toolName
}

const getToolDescription = (toolName, args) => {
  const descriptions = {
    'gdrive_list_files': `Buscando ${args.pageSize || 10} arquivos recentes`,
    'gdrive_read_file': `Lendo arquivo: ${args.fileName || 'documento'}`,
    'sheets_read_values': `Lendo planilha ${args.range || 'dados'}`,
    'sheets_write_values': `Escrevendo em planilha ${args.range || 'dados'}`
  }
  return descriptions[toolName] || 'Executando ferramenta'
}

// =====================================================
// FUN√á√ïES RAG (RETRIEVAL-AUGMENTED GENERATION)
// =====================================================

/**
 * Gera embeddings para um texto usando OpenAI
 */
async function generateEmbeddings(text) {
  try {
    // Tentar primeiro com text-embedding-3-large (3072 dimens√µes)
    // Se falhar, usar text-embedding-3-small (1536 dimens√µes)
    let response
    try {
      response = await openai.embeddings.create({
        model: 'text-embedding-3-large',
        input: text,
        encoding_format: 'float'
      })
    } catch (error) {
      console.warn('‚ö†Ô∏è text-embedding-3-large falhou, tentando text-embedding-3-small...')
      response = await openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: text,
        encoding_format: 'float'
      })
    }
    
    return response.data[0].embedding
  } catch (error) {
    console.error('‚ùå Erro ao gerar embeddings:', error)
    throw error
  }
}

/**
 * Busca chunks relevantes baseado na query do usu√°rio
 */
async function searchRelevantChunks(query, agentId, userId, limit = 5) {
  try {
    // 1. Gerar embedding da query
    const queryEmbedding = await generateEmbeddings(query)
    
    // 2. Buscar chunks similares usando cosine similarity
    const { data: chunks, error } = await supabase.rpc('match_chunks', {
      query_embedding: queryEmbedding,
      match_threshold: 0.1, // Threshold baixo para teste
      match_count: limit,
      agent_id_param: agentId,
      user_id_param: userId
    })
    
    if (error) {
      console.error('‚ùå Erro na busca de chunks:', error)
      return []
    }
    
    return chunks || []
  } catch (error) {
    console.error('‚ùå Erro na busca sem√¢ntica:', error)
    return []
  }
}

/**
 * Constr√≥i contexto RAG para o agente
 */
async function buildRAGContext(userMessage, agentId, userId) {
  try {
    // Buscar chunks relevantes
    const relevantChunks = await searchRelevantChunks(userMessage, agentId, userId)
    
    if (relevantChunks.length === 0) {
      return {
        hasContext: false,
        context: '',
        chunks: []
      }
    }
    
    // Construir contexto
    const context = relevantChunks
      .map(chunk => `[Fonte: ${chunk.file_name || 'Documento'}] ${chunk.content}`)
      .join('\n\n')
    
    return {
      hasContext: true,
      context: context,
      chunks: relevantChunks
    }
  } catch (error) {
    console.error('‚ùå Erro ao construir contexto RAG:', error)
    return {
      hasContext: false,
      context: '',
      chunks: []
    }
  }
}

// =====================================================
// FUN√á√ïES DE CHAT
// =====================================================

/**
 * Definir ferramentas MCP para OpenAI Function Calling
 */
const getMCPTools = () => [
  {
    type: "function",
    function: {
      name: "gdrive_list_files",
      description: "Lista arquivos do Google Drive do usu√°rio",
      parameters: {
        type: "object",
        properties: {
          pageSize: {
            type: "number",
            description: "N√∫mero m√°ximo de arquivos a retornar (padr√£o: 10)"
          }
        }
      }
    }
  },
  {
    type: "function",
    function: {
      name: "gdrive_read_file",
      description: "L√™ o conte√∫do de um arquivo espec√≠fico do Google Drive",
      parameters: {
        type: "object",
        properties: {
          fileId: {
            type: "string",
            description: "ID do arquivo no Google Drive"
          },
          fileName: {
            type: "string", 
            description: "Nome do arquivo para identifica√ß√£o"
          }
        },
        required: ["fileId"]
      }
    }
  },
  {
    type: "function", 
    function: {
      name: "sheets_read_values",
      description: "L√™ valores de uma planilha do Google Sheets",
      parameters: {
        type: "object",
        properties: {
          spreadsheetId: {
            type: "string",
            description: "ID da planilha do Google Sheets"
          },
          range: {
            type: "string", 
            description: "Intervalo de c√©lulas (ex: A1:B10)"
          }
        },
        required: ["spreadsheetId", "range"]
      }
    }
  },
  {
    type: "function",
    function: {
      name: "sheets_write_values", 
      description: "Escreve valores em uma planilha do Google Sheets",
      parameters: {
        type: "object",
        properties: {
          spreadsheetId: {
            type: "string",
            description: "ID da planilha do Google Sheets"
          },
          range: {
            type: "string",
            description: "Intervalo de c√©lulas (ex: A1:B10)"
          },
          values: {
            type: "array",
            description: "Array de arrays com os valores a escrever",
            items: {
              type: "array",
              items: {
                type: "string"
              }
            }
          }
        },
        required: ["spreadsheetId", "range", "values"]
      }
    }
  }
]

/**
 * Gera resposta usando OpenAI com contexto RAG e MCP tools com SSE
 */
async function generateAIResponseWithSSE(prompt, message, ragContext = null, userId = null, agentId = null, sendEvent) {
  try {
    // Construir o prompt do sistema
    let systemPrompt = prompt
    
    // Adicionar contexto RAG se dispon√≠vel
    if (ragContext && ragContext.hasContext) {
      systemPrompt = `${prompt}

IMPORTANTE - BASE DE CONHECIMENTO:
Use as seguintes informa√ß√µes dos documentos carregados para responder √† pergunta do usu√°rio. Se a pergunta estiver relacionada ao conte√∫do dos documentos, baseie sua resposta neles:

${ragContext.context}

INSTRU√á√ïES:
- Sempre que poss√≠vel, use informa√ß√µes da base de conhecimento para fornecer respostas precisas e detalhadas
- Se n√£o encontrar informa√ß√µes relevantes nos documentos, informe ao usu√°rio que n√£o tem dados suficientes sobre o assunto
- Cite a fonte dos documentos quando usar informa√ß√µes deles
- Mantenha as respostas concisas e diretas`
    } else {
      systemPrompt = `${prompt}

NOTA: N√£o h√° documentos espec√≠ficos carregados na base de conhecimento para este agente. Responda baseado no seu conhecimento geral.`
    }

    // Adicionar instru√ß√µes para MCP tools
    systemPrompt += `

FERRAMENTAS DISPON√çVEIS:
Voc√™ tem acesso √†s seguintes ferramentas do Google:
- gdrive_list_files: Para listar arquivos do Google Drive
- gdrive_read_file: Para ler o conte√∫do de um arquivo espec√≠fico do Google Drive (requer fileId)
- sheets_read_values: Para ler dados de planilhas Google Sheets (requer spreadsheetId V√ÅLIDO)
- sheets_write_values: Para escrever dados em planilhas Google Sheets

REGRAS OBRIGAT√ìRIAS:

1. CONTEXTO DE CONVERSA:
   - SEMPRE considere o contexto das mensagens anteriores na conversa
   - Se o usu√°rio se refere a "essa planilha" ou "esse arquivo", use o CONTE√öDO j√° obtido anteriormente
   - N√ÉO invente IDs de planilhas ou arquivos inexistentes

2. GOOGLE DRIVE:
   - Para ler arquivos: use gdrive_list_files ‚Üí gdrive_read_file
   - SEMPRE execute AMBAS as ferramentas para completar a tarefa
   - NUNCA responda que "encontrou" sem ler o conte√∫do

3. GOOGLE SHEETS:
   - CR√çTICO: Use APENAS IDs do Google Drive j√° listados na conversa
   - O spreadsheetId deve ser o campo "id" dos arquivos listados pelo gdrive_list_files
   - EXEMPLO: Para "DESTINAT√ÅRIOS" use ID "1PFCr8WqbvfxUTAJvpYmlvgs2vj-AaaYSmOBEEJe9aC0"
   - NUNCA use o nome do arquivo como ID (ex: "DESTINATARIOS" √© ERRADO)
   - NUNCA use IDs gen√©ricos como "1", "sheet1", etc.
   - Se n√£o encontrar o ID na conversa, use gdrive_list_files primeiro
   
   REGRAS PARA ESCRITA SEGURA:
   - SEMPRE leia a planilha ANTES de escrever (use sheets_read_values primeiro)
   - NUNCA escreva em A1 ou c√©lulas que podem conter dados importantes
   - Encontre uma c√©lula vazia ou uma nova linha para adicionar dados
   - Se incerto sobre onde escrever, PERGUNTE ao usu√°rio
   - Para adicionar dados, use a pr√≥xima linha vazia dispon√≠vel
   
   REGRAS PARA REMO√á√ÉO/LIMPEZA:
   - Para REMOVER dados: use sheets_write_values com c√©lulas vazias [""]
   - SEMPRE leia primeiro para identificar a linha/coluna correta
   - CR√çTICO: CONTE as linhas com CUIDADO (linha 1 = A1, linha 2 = A2, etc.)
   - VERIFIQUE o valor EXATO na planilha antes de determinar a linha
   - IMPORTANTE: Remova TODA A LINHA, n√£o apenas uma c√©lula
   - OBRIGAT√ìRIO: Use range que inclua TODAS as colunas da linha
   - EXEMPLO: Se o n√∫mero est√° em A7, use range "A7:B7", values [["", ""]]
   - NUNCA assuma a posi√ß√£o - sempre confirme pelo conte√∫do lido
   - CONFIRME o que foi removido depois da opera√ß√£o

4. AN√ÅLISE DE DADOS:
   - Se o usu√°rio pedir an√°lise de dados j√° obtidos, use o CONTE√öDO j√° lido
   - N√ÉO tente buscar novamente com IDs inventados
   - Processe os dados dispon√≠veis na conversa atual
   - SEMPRE fa√ßa an√°lises PRECISAS e DETALHADAS dos dados
   - Para ADICIONAR dados a planilhas existentes, primeiro LEIA o conte√∫do atual
   - IDENTIFIQUE onde h√° espa√ßo vazio para adicionar novos dados
   - CORRESPOND√äNCIA EXATA: Quando localizar um valor, determine sua posi√ß√£o baseada no array retornado
   - EXEMPLO: Se sheets_read_values retorna ["5581982408541", "5519999054433", "5581987654321"]
     ent√£o "5581987654321" est√° no √≠ndice 2 (terceiro item) = linha 3 (A3)

5. N√öMEROS DE TELEFONE BRASILEIROS:
   - Formato: 55 + DDD + n√∫mero (ex: 5581987654321)
   - DDD 81 = Recife/PE, DDD 11 = S√£o Paulo, DDD 21 = Rio de Janeiro, DDD 19 = Campinas
   - Para identificar DDD, olhe os DOIS d√≠gitos ap√≥s "55"
   - Exemplo: 5581982408541 ‚Üí DDD 81 (Recife), 5519999054433 ‚Üí DDD 19 (Campinas)
   - SEMPRE verifique CUIDADOSAMENTE os DDDs antes de categorizar

Use essas ferramentas SOMENTE quando necess√°rio e com par√¢metros V√ÅLIDOS.`

    // Construir array de mensagens com hist√≥rico
    const messages = [
      {
        role: 'system',
        content: systemPrompt
      }
    ]

    // Adicionar hist√≥rico da conversa (se existir)
    if (conversationHistory.length > 0) {
      console.log(`üí≠ Incluindo ${conversationHistory.length} mensagens do hist√≥rico`)
      conversationHistory.forEach(msg => {
        messages.push({
          role: msg.role,
          content: msg.content
        })
      })
    }

    // Adicionar mensagem atual do usu√°rio
    messages.push({
      role: 'user',
      content: message
    })

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: messages,
      tools: getMCPTools(),
      tool_choice: "auto",
      max_tokens: 1000,
      temperature: 0.7
    })

    const responseMessage = response.choices[0].message

    // Se a IA decidiu usar uma ferramenta
    if (responseMessage.tool_calls) {
      sendEvent('tools_requested', { 
        count: responseMessage.tool_calls.length,
        message: `OpenAI solicitou ${responseMessage.tool_calls.length} ferramenta(s)`
      })
      
      const toolResults = []
      
      for (const toolCall of responseMessage.tool_calls) {
        try {
          const functionName = toolCall.function.name
          const functionArgs = JSON.parse(toolCall.function.arguments)
          
          // Enviar evento de in√≠cio da ferramenta
          sendEvent('tool_start', {
            name: functionName,
            displayName: getToolDisplayName(functionName),
            description: getToolDescription(functionName, functionArgs),
            args: functionArgs
          })
          
          // Executar a ferramenta MCP correspondente
          const result = await executeMCPTool(functionName, functionArgs, userId)
          
          // Enviar evento de sucesso da ferramenta
          sendEvent('tool_success', {
            name: functionName,
            displayName: getToolDisplayName(functionName)
          })
          
          toolResults.push({
            tool_call_id: toolCall.id,
            role: "tool",
            content: JSON.stringify(result)
          })
        } catch (error) {
          console.error(`‚ùå Erro ao executar ferramenta ${toolCall.function.name}:`, error)
          
          // Enviar evento de erro da ferramenta
          sendEvent('tool_error', {
            name: toolCall.function.name,
            error: error.message
          })
          
          toolResults.push({
            tool_call_id: toolCall.id,
            role: "tool", 
            content: JSON.stringify({ error: error.message })
          })
        }
      }

      sendEvent('second_ai_call', { message: 'Fazendo segunda chamada √† OpenAI...' })
      
      // Fazer uma segunda chamada √† OpenAI com os resultados das ferramentas
      const finalResponse = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: message
          },
          responseMessage,
          ...toolResults
        ],
        tools: getMCPTools(),
        tool_choice: "auto",
        max_tokens: 1000,
        temperature: 0.7
      })

      const finalMessage = finalResponse.choices[0].message

      // Se a OpenAI quer usar mais ferramentas, executar recursivamente
      if (finalMessage.tool_calls) {
        sendEvent('additional_tools', { 
          count: finalMessage.tool_calls.length,
          message: `OpenAI solicitou ${finalMessage.tool_calls.length} ferramenta(s) adicional(is)`
        })
        
        const additionalToolResults = []
        for (const toolCall of finalMessage.tool_calls) {
          try {
            const functionName = toolCall.function.name
            const functionArgs = JSON.parse(toolCall.function.arguments)
            
            sendEvent('tool_start', {
              name: functionName,
              displayName: getToolDisplayName(functionName),
              description: getToolDescription(functionName, functionArgs),
              args: functionArgs
            })
            
            const result = await executeMCPTool(functionName, functionArgs, userId)
            
            sendEvent('tool_success', {
              name: functionName,
              displayName: getToolDisplayName(functionName)
            })
            
            additionalToolResults.push({
              tool_call_id: toolCall.id,
              role: "tool",
              content: JSON.stringify(result)
            })
          } catch (error) {
            console.error(`‚ùå Erro ao executar ferramenta adicional ${toolCall.function.name}:`, error)
            
            sendEvent('tool_error', {
              name: toolCall.function.name,
              error: error.message
            })
            
            additionalToolResults.push({
              tool_call_id: toolCall.id,
              role: "tool",
              content: JSON.stringify({ error: error.message })
            })
          }
        }

        sendEvent('final_ai_call', { message: 'Chamada final √† OpenAI...' })

        // Chamada final para gerar a resposta com todos os resultados
        const ultimateResponse = await openai.chat.completions.create({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: systemPrompt
            },
            {
              role: 'user',
              content: message
            },
            responseMessage,
            ...toolResults,
            finalMessage,
            ...additionalToolResults
          ],
          max_tokens: 1000,
          temperature: 0.7
        })

        return ultimateResponse.choices[0].message.content
      }

      return finalMessage.content
    }

    return responseMessage.content
  } catch (error) {
    console.error('‚ùå Erro ao gerar resposta da IA:', error)
    sendEvent('ai_error', { error: error.message })
    throw error
  }
}

/**
 * Gera resposta usando OpenAI com contexto RAG e MCP tools (vers√£o tradicional)
 */
async function generateAIResponse(prompt, message, ragContext = null, userId = null, agentId = null, req = null, sessionId = null, conversationHistory = []) {
  try {
    // Inicializar array para rastrear ferramentas executadas
    const toolsExecuted = []
    
    // Construir o prompt do sistema
    let systemPrompt = prompt
    
    // Adicionar contexto RAG se dispon√≠vel
    if (ragContext && ragContext.hasContext) {
      systemPrompt = `${prompt}

IMPORTANTE - BASE DE CONHECIMENTO:
Use as seguintes informa√ß√µes dos documentos carregados para responder √† pergunta do usu√°rio. Se a pergunta estiver relacionada ao conte√∫do dos documentos, baseie sua resposta neles:

${ragContext.context}

INSTRU√á√ïES:
- Sempre que poss√≠vel, use informa√ß√µes da base de conhecimento para fornecer respostas precisas e detalhadas
- Se n√£o encontrar informa√ß√µes relevantes nos documentos, informe ao usu√°rio que n√£o tem dados suficientes sobre o assunto
- Cite a fonte dos documentos quando usar informa√ß√µes deles
- Mantenha as respostas concisas e diretas`
    } else {
      systemPrompt = `${prompt}

NOTA: N√£o h√° documentos espec√≠ficos carregados na base de conhecimento para este agente. Responda baseado no seu conhecimento geral.`
    }

    // Adicionar instru√ß√µes para MCP tools
    systemPrompt += `

FERRAMENTAS DISPON√çVEIS:
Voc√™ tem acesso √†s seguintes ferramentas do Google:
- gdrive_list_files: Para listar arquivos do Google Drive
- gdrive_read_file: Para ler o conte√∫do de um arquivo espec√≠fico do Google Drive (requer fileId)
- sheets_read_values: Para ler dados de planilhas Google Sheets (requer spreadsheetId V√ÅLIDO)
- sheets_write_values: Para escrever dados em planilhas Google Sheets

REGRAS OBRIGAT√ìRIAS:

1. CONTEXTO DE CONVERSA:
   - SEMPRE considere o contexto das mensagens anteriores na conversa
   - Se o usu√°rio se refere a "essa planilha" ou "esse arquivo", use o CONTE√öDO j√° obtido anteriormente
   - N√ÉO invente IDs de planilhas ou arquivos inexistentes

2. GOOGLE DRIVE:
   - Para ler arquivos: use gdrive_list_files ‚Üí gdrive_read_file
   - SEMPRE execute AMBAS as ferramentas para completar a tarefa
   - NUNCA responda que "encontrou" sem ler o conte√∫do

3. GOOGLE SHEETS:
   - CR√çTICO: Use APENAS IDs do Google Drive j√° listados na conversa
   - O spreadsheetId deve ser o campo "id" dos arquivos listados pelo gdrive_list_files
   - EXEMPLO: Para "DESTINAT√ÅRIOS" use ID "1PFCr8WqbvfxUTAJvpYmlvgs2vj-AaaYSmOBEEJe9aC0"
   - NUNCA use o nome do arquivo como ID (ex: "DESTINATARIOS" √© ERRADO)
   - NUNCA use IDs gen√©ricos como "1", "sheet1", etc.
   - Se n√£o encontrar o ID na conversa, use gdrive_list_files primeiro
   
   REGRAS PARA ESCRITA SEGURA:
   - SEMPRE leia a planilha ANTES de escrever (use sheets_read_values primeiro)
   - NUNCA escreva em A1 ou c√©lulas que podem conter dados importantes
   - Encontre uma c√©lula vazia ou uma nova linha para adicionar dados
   - Se incerto sobre onde escrever, PERGUNTE ao usu√°rio
   - Para adicionar dados, use a pr√≥xima linha vazia dispon√≠vel
   
   REGRAS PARA REMO√á√ÉO/LIMPEZA:
   - Para REMOVER dados: use sheets_write_values com c√©lulas vazias [""]
   - SEMPRE leia primeiro para identificar a linha/coluna correta
   - CR√çTICO: CONTE as linhas com CUIDADO (linha 1 = A1, linha 2 = A2, etc.)
   - VERIFIQUE o valor EXATO na planilha antes de determinar a linha
   - IMPORTANTE: Remova TODA A LINHA, n√£o apenas uma c√©lula
   - OBRIGAT√ìRIO: Use range que inclua TODAS as colunas da linha
   - EXEMPLO: Se o n√∫mero est√° em A7, use range "A7:B7", values [["", ""]]
   - NUNCA assuma a posi√ß√£o - sempre confirme pelo conte√∫do lido
   - CONFIRME o que foi removido depois da opera√ß√£o

4. AN√ÅLISE DE DADOS:
   - Se o usu√°rio pedir an√°lise de dados j√° obtidos, use o CONTE√öDO j√° lido
   - N√ÉO tente buscar novamente com IDs inventados
   - Processe os dados dispon√≠veis na conversa atual
   - SEMPRE fa√ßa an√°lises PRECISAS e DETALHADAS dos dados
   - Para ADICIONAR dados a planilhas existentes, primeiro LEIA o conte√∫do atual
   - IDENTIFIQUE onde h√° espa√ßo vazio para adicionar novos dados
   - CORRESPOND√äNCIA EXATA: Quando localizar um valor, determine sua posi√ß√£o baseada no array retornado
   - EXEMPLO: Se sheets_read_values retorna ["5581982408541", "5519999054433", "5581987654321"]
     ent√£o "5581987654321" est√° no √≠ndice 2 (terceiro item) = linha 3 (A3)

5. N√öMEROS DE TELEFONE BRASILEIROS:
   - Formato: 55 + DDD + n√∫mero (ex: 5581987654321)
   - DDD 81 = Recife/PE, DDD 11 = S√£o Paulo, DDD 21 = Rio de Janeiro, DDD 19 = Campinas
   - Para identificar DDD, olhe os DOIS d√≠gitos ap√≥s "55"
   - Exemplo: 5581982408541 ‚Üí DDD 81 (Recife), 5519999054433 ‚Üí DDD 19 (Campinas)
   - SEMPRE verifique CUIDADOSAMENTE os DDDs antes de categorizar

Use essas ferramentas SOMENTE quando necess√°rio e com par√¢metros V√ÅLIDOS.`

    // Construir array de mensagens com hist√≥rico
    const messages = [
      {
        role: 'system',
        content: systemPrompt
      }
    ]

    // Adicionar hist√≥rico da conversa (se existir)
    if (conversationHistory.length > 0) {
      console.log(`üí≠ Incluindo ${conversationHistory.length} mensagens do hist√≥rico`)
      conversationHistory.forEach(msg => {
        messages.push({
          role: msg.role,
          content: msg.content
        })
      })
    }

    // Adicionar mensagem atual do usu√°rio
    messages.push({
      role: 'user',
      content: message
    })

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: messages,
      tools: getMCPTools(),
      tool_choice: "auto",
      max_tokens: 1000,
      temperature: 0.7
    })

    const responseMessage = response.choices[0].message

    // Se a IA decidiu usar uma ferramenta
    if (responseMessage.tool_calls) {
      console.log(`üîß OpenAI solicitou ${responseMessage.tool_calls.length} ferramenta(s)`)
      const toolResults = []
      
      // Inicializar array de ferramentas executadas
      if (req) {
        req.toolsExecuted = req.toolsExecuted || []
      }
      
      // Notificar in√≠cio das ferramentas via SSE
      if (sessionId) {
        sendToolEvent(sessionId, 'tools_requested', {
          count: responseMessage.tool_calls.length,
          tools: responseMessage.tool_calls.map(tc => tc.function.name)
        })
      }
      
      for (const toolCall of responseMessage.tool_calls) {
        const functionName = toolCall.function.name
        const functionArgs = JSON.parse(toolCall.function.arguments)
        
        console.log(`üîß Executando ferramenta MCP: ${functionName} com args:`, functionArgs)
        
        // Adicionar ferramenta ao tracking
        const toolInfo = {
          name: functionName,
          displayName: getToolDisplayName(functionName),
          description: getToolDescription(functionName, functionArgs),
          status: 'executing',
          timestamp: new Date().toISOString(),
          args: functionArgs
        }
        
        if (req) {
          req.toolsExecuted.push(toolInfo)
        }
        
        // Notificar in√≠cio da ferramenta via SSE
        if (sessionId) {
          sendToolEvent(sessionId, 'tool_start', {
            name: functionName,
            displayName: getToolDisplayName(functionName),
            description: getToolDescription(functionName, functionArgs),
            args: functionArgs
          })
        }
        
        try {
          // Executar a ferramenta MCP correspondente
          const result = await executeMCPTool(functionName, functionArgs, userId)
          console.log(`‚úÖ Ferramenta ${functionName} executada com sucesso`)
          
          // Atualizar status para sucesso
          if (req && toolInfo) {
            toolInfo.status = 'success'
            toolInfo.completedAt = new Date().toISOString()
            toolInfo.result = result
          }
          
          // Notificar sucesso da ferramenta via SSE
          if (sessionId) {
            sendToolEvent(sessionId, 'tool_success', {
              name: functionName,
              displayName: getToolDisplayName(functionName),
              result: result
            })
          }
          
          toolResults.push({
            tool_call_id: toolCall.id,
            role: "tool",
            content: JSON.stringify(result)
          })
        } catch (error) {
          console.error(`‚ùå Erro ao executar ferramenta ${functionName}:`, error)
          
          // Atualizar status para erro
          if (req && toolInfo) {
            toolInfo.status = 'error'
            toolInfo.error = error.message || 'Erro desconhecido na execu√ß√£o da ferramenta'
            toolInfo.completedAt = new Date().toISOString()
          }
          
          // Notificar erro da ferramenta via SSE
          if (sessionId) {
            sendToolEvent(sessionId, 'tool_error', {
              name: functionName,
              displayName: getToolDisplayName(functionName),
              error: error.message || 'Erro desconhecido na execu√ß√£o da ferramenta'
            })
          }
          
          toolResults.push({
            tool_call_id: toolCall.id,
            role: "tool", 
            content: JSON.stringify({ error: error.message })
          })
        }
      }

      console.log(`üîÑ Fazendo segunda chamada √† OpenAI com ${toolResults.length} resultado(s)`)
      
      // Fazer uma segunda chamada √† OpenAI com os resultados das ferramentas
      const finalResponse = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: message
          },
          responseMessage,
          ...toolResults
        ],
        tools: getMCPTools(),
        tool_choice: "auto",
        max_tokens: 1000,
        temperature: 0.7
      })

      const finalMessage = finalResponse.choices[0].message

      // Se a OpenAI quer usar mais ferramentas, executar recursivamente
      if (finalMessage.tool_calls) {
        console.log(`üîß OpenAI solicitou ${finalMessage.tool_calls.length} ferramenta(s) adicional(is)`)
        
        // Notificar ferramentas adicionais via SSE
        if (sessionId) {
          sendToolEvent(sessionId, 'additional_tools_requested', {
            count: finalMessage.tool_calls.length,
            tools: finalMessage.tool_calls.map(tc => tc.function.name)
          })
        }
        
        const additionalToolResults = []
        for (const toolCall of finalMessage.tool_calls) {
          try {
            const functionName = toolCall.function.name
            const functionArgs = JSON.parse(toolCall.function.arguments)
            
            console.log(`üîß Executando ferramenta adicional: ${functionName} com args:`, functionArgs)
            
            // Notificar in√≠cio da ferramenta adicional via SSE
            if (sessionId) {
              sendToolEvent(sessionId, 'tool_start', {
                name: functionName,
                displayName: getToolDisplayName(functionName),
                description: getToolDescription(functionName, functionArgs),
                args: functionArgs,
                isAdditional: true
              })
            }
            
            const result = await executeMCPTool(functionName, functionArgs, userId)
            console.log(`‚úÖ Ferramenta adicional ${functionName} executada com sucesso`)
            
            // Notificar sucesso da ferramenta adicional via SSE
            if (sessionId) {
              sendToolEvent(sessionId, 'tool_success', {
                name: functionName,
                displayName: getToolDisplayName(functionName),
                result: result,
                isAdditional: true
              })
            }
            
            additionalToolResults.push({
              tool_call_id: toolCall.id,
              role: "tool",
              content: JSON.stringify(result)
            })
          } catch (error) {
            console.error(`‚ùå Erro ao executar ferramenta adicional ${toolCall.function.name}:`, error)
            
            // Notificar erro da ferramenta adicional via SSE
            if (sessionId) {
              sendToolEvent(sessionId, 'tool_error', {
                name: toolCall.function.name,
                displayName: getToolDisplayName(toolCall.function.name),
                error: error.message || 'Erro desconhecido na execu√ß√£o da ferramenta',
                isAdditional: true
              })
            }
            
            additionalToolResults.push({
              tool_call_id: toolCall.id,
              role: "tool",
              content: JSON.stringify({ error: error.message })
            })
          }
        }

        // Chamada final para gerar a resposta com todos os resultados (COM STREAMING)
        console.log(`üé¨ Iniciando streaming da resposta final...`)
        const ultimateResponse = await openai.chat.completions.create({
          model: 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: systemPrompt
            },
            {
              role: 'user',
              content: message
            },
            responseMessage,
            ...toolResults,
            finalMessage,
            ...additionalToolResults
          ],
          max_tokens: 1000,
          temperature: 0.7,
          stream: true // ‚ú® ATIVAR STREAMING
        })

        // Processar stream e enviar via SSE
        const finalContent = await handleOpenAIStreamResponse(ultimateResponse, sessionId)
        console.log(`‚úÖ Chamada final conclu√≠da com streaming`)
        return finalContent
      }

      // Se n√£o h√° ferramentas adicionais, fazer streaming da resposta final
      if (sessionId && finalMessage.content) {
        console.log(`üé¨ Iniciando streaming da resposta final (sem ferramentas adicionais)...`)
        // Simular streaming para consist√™ncia da UI
        sendTextStreamEvent(sessionId, 'text_start', { message: 'Iniciando resposta...' })
        
        // Enviar resposta completa como stream simulado
        const words = finalMessage.content.split(' ')
        let currentText = ''
        
        for (const word of words) {
          currentText += (currentText ? ' ' : '') + word
          sendTextStreamEvent(sessionId, 'text_chunk', { 
            content: word + ' ',
            fullContent: currentText 
          })
          
          // Pequeno delay para simular digita√ß√£o
          await new Promise(resolve => setTimeout(resolve, 50))
        }
        
        sendTextStreamEvent(sessionId, 'text_complete', { 
          fullContent: finalMessage.content 
        })
        
        console.log(`‚úÖ Streaming simulado conclu√≠do`)
      }
      
      console.log(`‚úÖ Segunda chamada √† OpenAI conclu√≠da`)
      return finalMessage.content
    }

    // Se n√£o h√° ferramentas, fazer streaming da primeira resposta
    if (sessionId && responseMessage.content) {
      console.log(`üé¨ Iniciando streaming da primeira resposta (sem ferramentas)...`)
      sendTextStreamEvent(sessionId, 'text_start', { message: 'Iniciando resposta...' })
      
      // Enviar resposta completa como stream simulado
      const words = responseMessage.content.split(' ')
      let currentText = ''
      
      for (const word of words) {
        currentText += (currentText ? ' ' : '') + word
        sendTextStreamEvent(sessionId, 'text_chunk', { 
          content: word + ' ',
          fullContent: currentText 
        })
        
        // Pequeno delay para simular digita√ß√£o
        await new Promise(resolve => setTimeout(resolve, 50))
      }
      
      sendTextStreamEvent(sessionId, 'text_complete', { 
        fullContent: responseMessage.content 
      })
      
      console.log(`‚úÖ Streaming simulado da primeira resposta conclu√≠do`)
    }

    return responseMessage.content
  } catch (error) {
    console.error('‚ùå Erro ao gerar resposta da IA:', error)
    throw error
  }
}

// =====================================================
// SISTEMA DE NOTIFICA√á√ïES SSE PARA FERRAMENTAS E TEXTO
// =====================================================

// Map para armazenar conex√µes SSE ativas por sessionId
const activeSSEConnections = new Map()

/**
 * Envia eventos de streaming de texto via SSE
 */
function sendTextStreamEvent(sessionId, eventType, data) {
  const sseRes = activeSSEConnections.get(sessionId)
  if (sseRes && !sseRes.destroyed) {
    try {
      sseRes.write(`event: ${eventType}\n`)
      sseRes.write(`data: ${JSON.stringify(data)}\n\n`)
    } catch (error) {
      console.error(`‚ùå Erro ao enviar evento SSE de texto para ${sessionId}:`, error)
      activeSSEConnections.delete(sessionId)
    }
  }
}

/**
 * Processa stream de resposta do OpenAI e envia via SSE
 */
async function handleOpenAIStreamResponse(stream, sessionId) {
  let fullContent = ''
  
  try {
    // Notificar in√≠cio do streaming
    sendTextStreamEvent(sessionId, 'text_start', { message: 'Iniciando resposta...' })
    
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || ''
      if (content) {
        fullContent += content
        
        // Enviar chunk de texto via SSE
        sendTextStreamEvent(sessionId, 'text_chunk', { 
          content: content,
          fullContent: fullContent 
        })
      }
    }
    
    // Notificar fim do streaming
    sendTextStreamEvent(sessionId, 'text_complete', { 
      fullContent: fullContent 
    })
    
    return fullContent
  } catch (error) {
    sendTextStreamEvent(sessionId, 'text_error', { 
      error: error.message 
    })
    throw error
  }
}

// Fun√ß√£o para enviar evento SSE para uma sess√£o espec√≠fica
function sendToolEvent(sessionId, eventType, data) {
  const connection = activeSSEConnections.get(sessionId)
  if (connection && !connection.destroyed) {
    try {
      connection.write(`event: ${eventType}\n`)
      connection.write(`data: ${JSON.stringify(data)}\n\n`)
    } catch (error) {
      console.error('‚ùå Erro ao enviar evento SSE:', error)
      activeSSEConnections.delete(sessionId)
    }
  }
}

// Endpoint SSE apenas para notifica√ß√µes de ferramentas
router.get('/:agentId/tools-stream/:sessionId', (req, res) => {
  const { sessionId } = req.params
  
  console.log(`üîó Nova conex√£o SSE para ferramentas: ${sessionId}`)
  
  // Configurar SSE
  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Cache-Control'
  })

  // Armazenar conex√£o
  activeSSEConnections.set(sessionId, res)
  
  // Enviar evento de conex√£o estabelecida
  sendToolEvent(sessionId, 'connected', { message: 'Conex√£o SSE estabelecida para ferramentas' })
  
  // Limpar conex√£o quando cliente desconectar
  req.on('close', () => {
    console.log(`üîå Conex√£o SSE fechada: ${sessionId}`)
    activeSSEConnections.delete(sessionId)
  })
  
  res.on('close', () => {
    console.log(`üîå Resposta SSE fechada: ${sessionId}`)
    activeSSEConnections.delete(sessionId)
  })
})

// =====================================================
// ENDPOINTS DA API
// =====================================================

// Endpoint SSE para streaming de progresso das ferramentas
router.get('/:agentId/stream', authenticateToken, async (req, res) => {
  // Configurar SSE
  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Cache-Control'
  })

  // Fun√ß√£o para enviar eventos
  const sendEvent = (type, data) => {
    res.write(`event: ${type}\n`)
    res.write(`data: ${JSON.stringify(data)}\n\n`)
  }

  // Manter conex√£o viva
  const keepAlive = setInterval(() => {
    res.write(': heartbeat\n\n')
  }, 30000)

  // Limpar quando cliente desconectar
  req.on('close', () => {
    clearInterval(keepAlive)
    res.end()
  })

  // Enviar evento inicial
  sendEvent('connected', { message: 'Conex√£o SSE estabelecida' })
})

// Enviar mensagem para o agente com streaming SSE (sem autentica√ß√£o para simplicidade)
router.get('/:agentId/stream', async (req, res) => {
  // Configurar SSE
  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Cache-Control'
  })

  const sendEvent = (type, data) => {
    res.write(`event: ${type}\n`)
    res.write(`data: ${JSON.stringify(data)}\n\n`)
  }

  try {
    const { agentId } = req.params
    const { message, conversationId, userId } = req.query
    
    // Para simplificar, vamos usar um userId fixo para teste
    // Em produ√ß√£o, voc√™ obteria isso da sess√£o ou contexto autenticado
    const actualUserId = userId || '55ccaa1e-34a2-42a2-ba1f-32dfb7c6320c'

    if (!message || !message.trim()) {
      sendEvent('error', { error: 'Mensagem √© obrigat√≥ria' })
      res.end()
      return
    }

    sendEvent('message_received', { message: message.substring(0, 100) + '...' })

    // Buscar informa√ß√µes do agente
    const { data: agent, error: agentError } = await supabase
      .from('agents')
      .select('*')
      .eq('id', agentId)
      .eq('user_id', actualUserId)
      .single()

    if (agentError || !agent) {
      sendEvent('error', { error: 'Agente n√£o encontrado' })
      res.end()
      return
    }

    sendEvent('agent_found', { agentName: agent.name })

    // Buscar contexto RAG
    sendEvent('searching_rag', { message: 'Buscando contexto RAG...' })
    const ragContext = await buildRAGContext(message, agentId, actualUserId)
    
    if (ragContext.hasContext) {
      sendEvent('rag_found', { chunksCount: ragContext.chunks.length })
    } else {
      sendEvent('rag_not_found', { message: 'Nenhum contexto RAG encontrado' })
    }

    // Gerar resposta da IA com streaming
    sendEvent('ai_generating', { message: 'Gerando resposta da IA...' })
    
    // Modificar a fun√ß√£o generateAIResponse para usar SSE
    const aiResponse = await generateAIResponseWithSSE(agent.prompt, message, ragContext, actualUserId, agentId, sendEvent)

    // Criar ou usar conversa existente
    let currentConversationId = conversationId
    if (!currentConversationId) {
      const { data: newConversation, error: convError } = await supabase
        .from('conversations')
        .insert({
          agent_id: agentId,
          user_id: userId,
          title: `Conversa com ${agent.name}`
        })
        .select()
        .single()

      if (convError) {
        sendEvent('error', { error: 'Erro ao criar conversa' })
        res.end()
        return
      }

      currentConversationId = newConversation.id
    }

    // Salvar mensagens
    await supabase.from('messages').insert({
      conversation_id: currentConversationId,
      content: message,
      role: 'user'
    })

    const { data: aiMessage } = await supabase
      .from('messages')
      .insert({
        conversation_id: currentConversationId,
        content: aiResponse,
        role: 'assistant'
      })
      .select()
      .single()

    // Atualizar timestamp da conversa
    await supabase
      .from('conversations')
      .update({ updated_at: new Date().toISOString() })
      .eq('id', currentConversationId)

    // Enviar resposta final
    sendEvent('response_complete', {
      id: aiMessage?.id || Date.now().toString(),
      content: aiResponse,
      role: 'assistant',
      timestamp: new Date().toISOString(),
      conversationId: currentConversationId
    })

    res.end()

  } catch (error) {
    console.error('‚ùå Erro no chat:', error)
    sendEvent('error', { error: 'Erro interno do servidor' })
    res.end()
  }
})

// Enviar mensagem para o agente (vers√£o tradicional)
router.post('/:agentId', authenticateToken, async (req, res) => {
  try {
    const { agentId } = req.params
    const { message, conversationId, sessionId } = req.body
    const userId = req.user.id

    if (!message || !message.trim()) {
      return res.status(400).json({ error: 'Mensagem √© obrigat√≥ria' })
    }

    console.log(`üí¨ Nova mensagem para agente ${agentId}: ${message.substring(0, 100)}...`)

    // Buscar informa√ß√µes do agente
    const { data: agent, error: agentError } = await supabase
      .from('agents')
      .select('*')
      .eq('id', agentId)
      .eq('user_id', userId)
      .single()

    if (agentError || !agent) {
      return res.status(404).json({ error: 'Agente n√£o encontrado' })
    }

    // Buscar contexto RAG
    console.log('üîç Buscando contexto RAG...')
    const ragContext = await buildRAGContext(message, agentId, userId)
    
    if (ragContext.hasContext) {
      console.log(`üìö Contexto RAG encontrado: ${ragContext.chunks.length} chunks`)
    } else {
      console.log('üìö Nenhum contexto RAG encontrado')
    }

    // Buscar hist√≥rico de mensagens da conversa atual (se existir)
    let conversationHistory = []
    if (conversationId) {
      const { data: messages } = await supabase
        .from('messages')
        .select('content, role, created_at')
        .eq('conversation_id', conversationId)
        .order('created_at', { ascending: true })
        .limit(20) // Limitar √∫ltimas 20 mensagens para n√£o sobrecarregar
      
      if (messages && messages.length > 0) {
        conversationHistory = messages
        console.log(`üí≠ Hist√≥rico encontrado: ${messages.length} mensagens`)
      }
    }

    // Gerar resposta da IA
    console.log('ü§ñ Gerando resposta da IA...')
    const aiResponse = await generateAIResponse(agent.prompt, message, ragContext, userId, agentId, req, sessionId, conversationHistory)

    // Criar ou usar conversa existente
    let currentConversationId = conversationId
    if (!currentConversationId) {
      const { data: newConversation, error: convError } = await supabase
        .from('conversations')
        .insert({
          agent_id: agentId,
          user_id: userId,
          title: `Conversa com ${agent.name}`
        })
        .select()
        .single()

      if (convError) {
        console.error('‚ùå Erro ao criar conversa:', convError)
        return res.status(500).json({ error: 'Erro ao criar conversa' })
      }

      currentConversationId = newConversation.id
    }

    // Salvar mensagem do usu√°rio
    const { error: userMsgError } = await supabase
      .from('messages')
      .insert({
        conversation_id: currentConversationId,
        content: message,
        role: 'user'
      })

    if (userMsgError) {
      console.error('‚ùå Erro ao salvar mensagem do usu√°rio:', userMsgError)
    }

    // Salvar resposta da IA
    const { data: aiMessage, error: aiMsgError } = await supabase
      .from('messages')
      .insert({
        conversation_id: currentConversationId,
        content: aiResponse,
        role: 'assistant'
      })
      .select()
      .single()

    if (aiMsgError) {
      console.error('‚ùå Erro ao salvar resposta da IA:', aiMsgError)
    }

    // Atualizar timestamp da conversa
    await supabase
      .from('conversations')
      .update({ updated_at: new Date().toISOString() })
      .eq('id', currentConversationId)

    console.log('‚úÖ Resposta gerada com sucesso')

    res.json({
      id: aiMessage?.id || Date.now().toString(),
      content: aiResponse,
      role: 'assistant',
      timestamp: new Date().toISOString(),
      conversationId: currentConversationId,
      ragContext: {
        hasContext: ragContext.hasContext,
        chunksCount: ragContext.chunks.length,
        sources: ragContext.chunks.map(chunk => chunk.file_name)
      },
      toolsExecuted: req.toolsExecuted || []
    })

  } catch (error) {
    console.error('‚ùå Erro no chat:', error)
    
    // Se for erro da API OpenAI, retornar mensagem espec√≠fica
    if (error.message.includes('OpenAI') || error.message.includes('API')) {
      return res.status(503).json({ 
        error: 'Servi√ßo de IA temporariamente indispon√≠vel. Tente novamente em alguns instantes.',
        details: error.message
      })
    }
    
    res.status(500).json({ error: 'Erro interno do servidor' })
  }
})

// Buscar hist√≥rico de conversas
router.get('/:agentId/conversations', authenticateToken, async (req, res) => {
  try {
    const { agentId } = req.params
    const userId = req.user.id

    const { data: conversations, error } = await supabase
      .from('conversations')
      .select(`
        id,
        title,
        created_at,
        updated_at,
        messages (
          id,
          content,
          role,
          created_at
        )
      `)
      .eq('agent_id', agentId)
      .eq('user_id', userId)
      .order('updated_at', { ascending: false })

    if (error) {
      console.error('‚ùå Erro ao buscar conversas:', error)
      return res.status(500).json({ error: 'Erro ao buscar conversas' })
    }

    res.json(conversations || [])
  } catch (error) {
    console.error('‚ùå Erro ao buscar conversas:', error)
    res.status(500).json({ error: 'Erro interno do servidor' })
  }
})

// Buscar mensagens de uma conversa espec√≠fica
router.get('/conversations/:conversationId/messages', authenticateToken, async (req, res) => {
  try {
    const { conversationId } = req.params
    const userId = req.user.id

    // Verificar se a conversa pertence ao usu√°rio
    const { data: conversation, error: convError } = await supabase
      .from('conversations')
      .select('id')
      .eq('id', conversationId)
      .eq('user_id', userId)
      .single()

    if (convError || !conversation) {
      return res.status(404).json({ error: 'Conversa n√£o encontrada' })
    }

    const { data: messages, error } = await supabase
      .from('messages')
      .select('*')
      .eq('conversation_id', conversationId)
      .order('created_at', { ascending: true })

    if (error) {
      console.error('‚ùå Erro ao buscar mensagens:', error)
      return res.status(500).json({ error: 'Erro ao buscar mensagens' })
    }

    res.json(messages || [])
  } catch (error) {
    console.error('‚ùå Erro ao buscar mensagens:', error)
    res.status(500).json({ error: 'Erro interno do servidor' })
  }
})

// Deletar conversa
router.delete('/conversations/:conversationId', authenticateToken, async (req, res) => {
  try {
    const { conversationId } = req.params
    const userId = req.user.id

    // Verificar se a conversa pertence ao usu√°rio
    const { data: conversation, error: convError } = await supabase
      .from('conversations')
      .select('id')
      .eq('id', conversationId)
      .eq('user_id', userId)
      .single()

    if (convError || !conversation) {
      return res.status(404).json({ error: 'Conversa n√£o encontrada' })
    }

    // Deletar conversa (as mensagens ser√£o deletadas automaticamente por CASCADE)
    const { error } = await supabase
      .from('conversations')
      .delete()
      .eq('id', conversationId)

    if (error) {
      console.error('‚ùå Erro ao deletar conversa:', error)
      return res.status(500).json({ error: 'Erro ao deletar conversa' })
    }

    res.json({ message: 'Conversa deletada com sucesso' })
  } catch (error) {
    console.error('‚ùå Erro ao deletar conversa:', error)
    res.status(500).json({ error: 'Erro interno do servidor' })
  }
})

// Endpoint para testar busca RAG
router.post('/:agentId/test-rag', authenticateToken, async (req, res) => {
  try {
    const { agentId } = req.params
    const { query } = req.body
    const userId = req.user.id

    if (!query) {
      return res.status(400).json({ error: 'Query √© obrigat√≥ria' })
    }

    // Verificar se o agente existe e pertence ao usu√°rio
    const { data: agent, error: agentError } = await supabase
      .from('agents')
      .select('id')
      .eq('id', agentId)
      .eq('user_id', userId)
      .single()

    if (agentError || !agent) {
      return res.status(404).json({ error: 'Agente n√£o encontrado' })
    }

    // Buscar contexto RAG
    const ragContext = await buildRAGContext(query, agentId, userId)

    // Buscar estat√≠sticas da base de conhecimento
    const { data: stats, error: statsError } = await supabase
      .from('knowledge_base')
      .select('chunks_count, file_size')
      .eq('agent_id', agentId)
      .eq('user_id', userId)

    if (statsError) {
      console.error('‚ùå Erro ao buscar estat√≠sticas:', statsError)
    }

    const totalFiles = stats?.length || 0
    const totalChunks = stats?.reduce((sum, file) => sum + (file.chunks_count || 0), 0) || 0

    res.json({
      query: query,
      hasContext: ragContext.hasContext,
      context: ragContext.context,
      chunks: ragContext.chunks,
      chunksCount: ragContext.chunks.length,
      stats: {
        totalFiles,
        totalChunks
      }
    })

  } catch (error) {
    console.error('‚ùå Erro no teste RAG:', error)
    res.status(500).json({ error: 'Erro interno do servidor' })
  }
})


export default router
